使用 pos + 分片实现共识

分片
按照账户的 id 进行分片
分片计划按照账户数量+节点数量进行动态调整
每个进行打包的节点在打包完成后要进行分片调整(分片调整需要计算和网路开销)
所有节点都有 state tree，block header；对所有的 block body 数据进行分片存储，减少存储压力，后续会尽可能通过分片的方式来减少冗余存储

节点的分片策略是在节点运行之后进行动态变更的
所有符合下一分片规则的节点会一起订阅下一分片的消息，一旦下一订阅的节点数量大于限制数量，就会进行分片

因为 DID 生成是用的 base58 做的 hash，所以最后字符串的每一位都有可能有 58 种可能

<!-- 扩张过程 -->

最开始都是 o 分片，然后根据自己的 id 最后一位，判断自己是否大于等于 29，去订阅 o-l 或 o-r
当 o-l 和 o-r 节点数量都到了一定量之后，进行分片
分片后的 o-l 再根据自己的倒数第二位是否大于等于 29，去订阅 o-l-l、o-l-r，依次类推，每往前进一位，分片数量\*2

<!-- 缩量过程 -->

当前分片的节点数量小于 64 时，会跟同层节点合并，比如 o-l-l-l 本来有 100 节点，但忽然降到 60，就会导致 o-l-l-r-？包括子分片在内的节点都回到 o-l-l，直到 o-l-l 可以分为 o-l-l-l 和 o-l-l-r
因为 DID 生成是随机的，所以不会存在非常严重的树不平衡的状态

至少保证在每个分片内有 64 个节点进行竞争打包
竞争打包是通过 pubsub 进行协商，协商的过程中如果单一竞争方大于 128 可以进行二分片

活跃度参数
因为完全依赖 pos 的话会有存在屯币的缺陷，需要引入活跃度作为打包节点选出的条件之一来平衡

proof of contribute 对网络的贡献？ POC
对网络的贡献 = ？，应该是一个动态计算的东西，随着时间的推移，它会动态改变
全节点参与 POC

如果有分叉，就选择 contribute 最大的一个链作为主链

时空：、、、？
每条数据都是一个时间的函数，输入是元数据+时间，输出是输入时间对应的结果数据
